{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c655c0a5-9241-4bc8-9322-890c55ff594a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "import contractions\n",
    "import math\n",
    "from itertools import chain\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import bigrams\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import re\n",
    "import string\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16dee94e-0696-44cc-acb6-ea0ea29f0ba0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client creating using default project: helio-staging\n"
     ]
    }
   ],
   "source": [
    "client = bigquery.Client(location=\"US\")\n",
    "print(\"Client creating using default project: {}\".format(client.project))\n",
    "\n",
    "client = bigquery.Client(location=\"US\", project=\"helio-staging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2af25a4-deb2-4e4a-a0af-8edfebd101d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_CUSTOM_STOPWORDS = [\n",
    "    \"bike\", \"nbsp\", \"crn\",\"sample\", \"bikes\", \"great\", \"good\", \"love\",\"like\", \"recommend\",\"smells\",\"collected\",\"part\",\"review\",\"promotion\",\"razor\",\n",
    "    \"shave\",\"shaving\",\"blade\",\"camille\",\"cantu\",\"daughter\",\"today\",\"kccc\",\"jessie\",\"miss\",\"fabric\",\"pillow\",\"softener\",\"or\",    \"tiktok\",\"OR\",\n",
    "     'Proov', 'proov','Natalist', 'natalist','Stix', 'stix','Clear Blue', 'blue','Modern Fertility', 'modern', 'free', 'app', 'mf', 'android', 'pinchme',\n",
    "    'Pregmate', 'pregmate', 'received','First Response', 'test', 'ovulation', 'none', 'see', 'store', 'day', 'month', 'amy', 'face', 'far', 'scan',\n",
    "    'it‚äôs','don‚äôt', 'using_minoxidil', '_oz','i‚äôm','moreread','using','stating',\n",
    "    'doesn‚äôt', 'classic','order','ordering', 'best', 'hard', 'seltzer', 'claw','never','got','ordered','white','product','high-noon','bottle','girl',\n",
    "    'read_lessread','read_moreread','lessread_le','le_stating','moreread_stating','scalp detox','le_serum',\n",
    "    'moreread_serum','i’ve_stem','hair_read','don’t_know','i’ve_bought', 'liquid_kinda', \"i'ḿ\"'use_serum','le_mus','read_serum','ingredient_us','oz_extreme',\n",
    "    'cell_serum','cell','stem','le','read','lessread','moreread','more','multi-colored—from_brown','findin_read','strengthening_hair','hair_oil','care_oil',\n",
    "    'hair','oil_hair','extreme_hair','hair_care','extreme','oz','_strengthening','used twice', 'oil_oil', 'customer',    'nan', 'read_moreread', 'noreferrer',\n",
    "    'noreferrer_farmer','farmer_dog/a','noreferrer_ollie/a','rel','noopener','blank_rel',\n",
    "    'rel_nofollow','blank','nofollow','target_blank','noopener_noreferrer','nofollower_noopener','nofollow_noopener',\"partake\",\"partake_cooky\", \"crunchy_cooky\",\"cooky_vegan\",\"madegood\",\"apple_jack\"\n",
    "]\n",
    "\n",
    "added_stopwords_li = [\n",
    "    \"it’s\",    \"'d\",    \"'s\",\n",
    "    \"n't\",    \"'m\",\n",
    "    \"i've\",    \"it's\",    \"'ve\",\n",
    "    \"'re\",    \"'ll\",    \"``\",    \"''\",    \"...\",    \"--\", \"https\",\n",
    "    \"voxbox\",    \"influenster\",    \"cracker\",    \"or\",    'it‚äôs',\n",
    "    'don‚äôt',    'i‚äôm',    'doesn‚äôt',    \"get\", \"also\",    \"even\",    \"since\", \"amy\"\n",
    "]\n",
    "\n",
    "REV_COLS = ['source_name',\n",
    "    'normalized_url',\n",
    "    'review_source_id',\n",
    "    'reviewer_source_id',\n",
    "    'brand_name',\n",
    "    'product_name',\n",
    "    'product_source_id',\n",
    "    'review_date',\n",
    "    'review_rating',\n",
    "    'review_content'\n",
    "]\n",
    "\n",
    "product_categories = ['Accessories',\n",
    "'Alcoholic Beverages',\n",
    "'Apparel & Footwear',\n",
    "'Food',\n",
    "'Food Establishments',\n",
    "'Health & Beauty Establishments',\n",
    "'Household Consumables',\n",
    "'Household Durables',\n",
    "'Other',\n",
    "'Pet Products',\n",
    "'Non-Alcoholic Beverages',\n",
    "'Personal Care & Beauty',\n",
    "'Retailers',\n",
    "'Sports & Outdoors'\n",
    "]\n",
    "\n",
    "drop_words = [\n",
    "    \n",
    "             \n",
    "             ]\n",
    "\n",
    "MIN_TERM_PCT = 0\n",
    "\n",
    "MAX_TERM_PCT = 100\n",
    "\n",
    "TERM_PERCENT_HEAD = 1\n",
    "\n",
    "TOP_N_WORDS = 8\n",
    "\n",
    "np.random.seed(42) # set seed for models for reproducibility\n",
    "\n",
    "stopwords_li = stopwords.words('english')\n",
    "punkts_li = list(string.punctuation)\n",
    "\n",
    "REVIEWS_PER_BRAND_TO_ANALYZE = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dffbc713-0195-474b-aa80-f62567231dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s, strip_str=\"=-_/\\+.:,'* 1234567890—\"):\n",
    "    custom_words_li = GROUP_CUSTOM_STOPWORDS + added_stopwords_li+stopwords_li + punkts_li + [\"\"]\n",
    "    return [w.lower().strip(strip_str) for w in word_tokenize(str(s)) if w.lower().strip(strip_str) not in custom_words_li]\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(w) for w in tokens]\n",
    "\n",
    "def unique_list(li):\n",
    "    deduped_li = list(set(li))\n",
    "    return deduped_li\n",
    "\n",
    "def bigram(tokens):\n",
    "    bi_tup = list(bigrams(tokens))\n",
    "    bi_li = ['_'.join(tup) for tup in bi_tup]\n",
    "    return bi_li\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c6003ff-0a89-4935-9b48-e1d5342d9ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_NAME = \"Chocolate\"\n",
    "# GROUP_NAME = 'Meat Substitutes'\n",
    "\n",
    "\n",
    "# When using Streamlit, leave list empty and un-comment cells below\n",
    "\n",
    "#Cereals\n",
    "NORMALIZED_URL_LI = [\n",
    "    \"jojoschocolate.com\",\n",
    "    \"lilys.com\",\n",
    "    \"hukitchen.com\",\n",
    "    \"eatingevolved.com\",\n",
    "    \"skinnydipped.com\",\n",
    "    \"unrealsnacks.com\",\n",
    "    \"tcho.com\",\n",
    "    \"hersheyland.com\",\n",
    "    \"tonyschocolonely.com\",\n",
    "    \"tazachocolate.com\",\n",
    "]\n",
    "\n",
    "PRIMARY_CATEGORIES = [\n",
    "    'Chocolate',\n",
    "]                      \n",
    "\n",
    "\n",
    "BRAND_NAME_LI = [\n",
    "    \"JOJO's\",\n",
    "    \"Lily's\",\n",
    "    \"Hu\",\n",
    "    \"Eating Evolved\",\n",
    "    \"Skinny Dipped\",\n",
    "    \"Unreal Snacks\",\n",
    "    \"TCHO\",\n",
    "    \"Bark Thins\",\n",
    "    \"Tony's Chocolonely\",\n",
    "    \"Taza Chocolate\",\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "brand_name_di = dict(zip(NORMALIZED_URL_LI, BRAND_NAME_LI))\n",
    "\n",
    "external_revs_list = []\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "PROD_CAT_EXCLUDE_LI = ['Pet Products']\n",
    "    \n",
    "PRODUCT_NAME_NOT_CONTAINS_LI = ['toothpaste']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "add85673-17ea-494c-8614-cdd9401b1583",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config = bigquery.QueryJobConfig(\n",
    "    query_parameters=[\n",
    "        bigquery.ArrayQueryParameter(\"url\", \"STRING\", NORMALIZED_URL_LI),\n",
    "        bigquery.ArrayQueryParameter(\"cols\", \"STRING\", REV_COLS),\n",
    "        bigquery.ArrayQueryParameter(\"brands\", \"STRING\", BRAND_NAME_LI)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f31c7b3-7d98-4b73-9b7d-d4c591eddd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config = bigquery.QueryJobConfig(\n",
    "        query_parameters=[\n",
    "            bigquery.ArrayQueryParameter(\"url\", \"STRING\", NORMALIZED_URL_LI)\n",
    "        ]\n",
    ")\n",
    "max_date_query = \"\"\"\n",
    "    SELECT max(execution_date)\n",
    "    FROM `helio-staging.online_reviews.online_reviews__deduped_review__1_0`\n",
    "    where execution_date > DATE_ADD(current_date(), INTERVAL -10 DAY)\n",
    "    and normalized_url IS NOT NULL\n",
    "    \"\"\"\n",
    "query_job = client.query(\n",
    "    max_date_query,\n",
    "    # Location must match that of the dataset(s) referenced in the query.\n",
    "    location=\"US\",\n",
    "    job_config=job_config\n",
    ")  # API request - starts the query\n",
    "\n",
    "max_date = query_job.to_dataframe()['f0_'].astype('str')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "371c150b-6121-4f28-aec9-b6b3fa03e903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-02-27'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69689fb1-05b6-4091-92c6-a61bd52134f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config = bigquery.QueryJobConfig(\n",
    "    query_parameters=[\n",
    "        bigquery.ArrayQueryParameter(\"url\", \"STRING\", NORMALIZED_URL_LI),\n",
    "        bigquery.ScalarQueryParameter(\"max_date\", \"STRING\", max_date)\n",
    "    ]\n",
    ")\n",
    "review_query = \"\"\"\n",
    "    SELECT source_name,\n",
    "    normalized_url,\n",
    "    review_source_id,\n",
    "    reviewer_source_id,\n",
    "    product_name,\n",
    "    product_source_id,\n",
    "    review_date,\n",
    "    review_rating,\n",
    "    review_content\n",
    "    FROM `helio-staging.online_reviews.online_reviews__deduped_review__1_0`\n",
    "    WHERE normalized_url IN UNNEST (@url)\n",
    "    AND execution_date = @max_date\n",
    "    \"\"\"\n",
    "query_job = client.query(\n",
    "    review_query,\n",
    "    # Location must match that of the dataset(s) referenced in the query.\n",
    "    location=\"US\",\n",
    "    job_config=job_config\n",
    ")  # API request - starts the query\n",
    "\n",
    "reviews = query_job.to_dataframe()\n",
    "reviews = reviews.loc[reviews.astype(str).drop_duplicates().index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65bc99a0-ed54-4903-b720-8b40f9cce902",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTAINING_LI = [\"Obsessed\",\n",
    "                 \"loved|love|like\",\n",
    "                 \"hate\",\n",
    "                ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d647921f-8214-4d6e-a711-c29ccd370f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0bf11c9-7592-4b6c-b6ee-c1865c747832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Containing: Obsessed\n",
      "normalized_url\n",
      "eatingevolved.com        4\n",
      "hersheyland.com         66\n",
      "hukitchen.com            6\n",
      "jojoschocolate.com       1\n",
      "lilys.com                2\n",
      "skinnydipped.com         1\n",
      "tonyschocolonely.com     1\n",
      "unrealsnacks.com         1\n",
      "Name: review_content, dtype: int64\n",
      "Containing: loved|love|like\n",
      "normalized_url\n",
      "eatingevolved.com         488\n",
      "hersheyland.com         87613\n",
      "hukitchen.com            1090\n",
      "jojoschocolate.com        628\n",
      "lilys.com                3450\n",
      "skinnydipped.com          616\n",
      "tazachocolate.com        1654\n",
      "tcho.com                  727\n",
      "tonyschocolonely.com      493\n",
      "unrealsnacks.com          244\n",
      "Name: review_content, dtype: int64\n",
      "Containing: hate\n",
      "normalized_url\n",
      "eatingevolved.com         13\n",
      "hersheyland.com         1659\n",
      "hukitchen.com             17\n",
      "jojoschocolate.com         6\n",
      "lilys.com                 71\n",
      "skinnydipped.com          10\n",
      "tazachocolate.com         43\n",
      "tcho.com                   5\n",
      "tonyschocolonely.com       9\n",
      "unrealsnacks.com           4\n",
      "Name: review_content, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in CONTAINING_LI:\n",
    "    print(\"Containing: \" + i)\n",
    "    print(reviews[reviews[\"review_content\"].str.contains(i, na=False)].groupby(\"normalized_url\")[\"review_content\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647a48c-d5e2-4c05-8215-1949b6d33840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ede87e-29f5-4702-ab14-b9f8c7022e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
