{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "208f4558-985e-49d8-a84d-d66fe28a417f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f2cf8f5-fd3e-4a92-8ff5-df6f9b8af487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "import contractions\n",
    "import math\n",
    "from itertools import chain\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import bigrams\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import re\n",
    "import string\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "import pysheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af189897-3888-44b6-9873-2da63a1ef32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client creating using default project: helio-staging\n"
     ]
    }
   ],
   "source": [
    "client = bigquery.Client(location=\"US\")\n",
    "print(\"Client creating using default project: {}\".format(client.project))\n",
    "\n",
    "client = bigquery.Client(location=\"US\", project=\"helio-staging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86babbf-09b8-4dcd-b3c9-bfee960f2ca6",
   "metadata": {},
   "source": [
    "# Constants + Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cbd1e64-230c-4216-97b0-eb65ec2088b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_CUSTOM_STOPWORDS = [\n",
    "    \"bike\", \"nbsp\", \"crn\",\"sample\", \"bikes\", \"great\", \"good\", \"love\",\"like\", \"recommend\",\"smells\",\"collected\",\"part\",\"review\",\"promotion\",\"razor\",\n",
    "    \"shave\",\"shaving\",\"blade\",\"camille\",\"cantu\",\"daughter\",\"today\",\"kccc\",\"jessie\",\"miss\",\"fabric\",\"pillow\",\"softener\",\"or\",    \"tiktok\",\"OR\",\n",
    "     'Proov', 'proov','Natalist', 'natalist','Stix', 'stix','Clear Blue', 'blue','Modern Fertility', 'modern', 'free', 'app', 'mf', 'android', 'pinchme',\n",
    "    'Pregmate', 'pregmate', 'received','First Response', 'test', 'ovulation', 'none', 'see', 'store', 'day', 'month', 'amy', 'face', 'far', 'scan',\n",
    "    'it‚äôs','don‚äôt', 'using_minoxidil', '_oz','i‚äôm','moreread','using','stating',\n",
    "    'doesn‚äôt', 'classic','order','ordering', 'best', 'hard', 'seltzer', 'claw','never','got','ordered','white','product','high-noon','bottle','girl',\n",
    "    'read_lessread','read_moreread','lessread_le','le_stating','moreread_stating','scalp detox','le_serum',\n",
    "    'moreread_serum','i’ve_stem','hair_read','don’t_know','i’ve_bought', 'liquid_kinda', \"i'ḿ\"'use_serum','le_mus','read_serum','ingredient_us','oz_extreme',\n",
    "    'cell_serum','cell','stem','le','read','lessread','moreread','more','multi-colored—from_brown','findin_read','strengthening_hair','hair_oil','care_oil',\n",
    "    'hair','oil_hair','extreme_hair','hair_care','extreme','oz','_strengthening','used twice', 'oil_oil', 'customer',    'nan', 'read_moreread', 'noreferrer',\n",
    "    'noreferrer_farmer','farmer_dog/a','noreferrer_ollie/a','rel','noopener','blank_rel',\n",
    "    'rel_nofollow','blank','nofollow','target_blank','noopener_noreferrer','nofollower_noopener','nofollow_noopener',\"partake\",\"partake_cooky\", \"crunchy_cooky\",\"cooky_vegan\",\"madegood\",\"apple_jack\"\n",
    "]\n",
    "\n",
    "added_stopwords_li = [\n",
    "    \"it’s\",    \"'d\",    \"'s\",\n",
    "    \"n't\",    \"'m\",\n",
    "    \"i've\",    \"it's\",    \"'ve\",\n",
    "    \"'re\",    \"'ll\",    \"``\",    \"''\",    \"...\",    \"--\", \"https\",\n",
    "    \"voxbox\",    \"influenster\",    \"cracker\",    \"or\",    'it‚äôs',\n",
    "    'don‚äôt',    'i‚äôm',    'doesn‚äôt',    \"get\", \"also\",    \"even\",    \"since\", \"amy\"\n",
    "]\n",
    "\n",
    "REV_COLS = ['source_name',\n",
    "    'normalized_url',\n",
    "    'review_source_id',\n",
    "    'reviewer_source_id',\n",
    "    'brand_name',\n",
    "    'product_name',\n",
    "    'product_source_id',\n",
    "    'review_date',\n",
    "    'review_rating',\n",
    "    'review_content'\n",
    "]\n",
    "\n",
    "product_categories = ['Accessories',\n",
    "'Alcoholic Beverages',\n",
    "'Apparel & Footwear',\n",
    "'Food',\n",
    "'Food Establishments',\n",
    "'Health & Beauty Establishments',\n",
    "'Household Consumables',\n",
    "'Household Durables',\n",
    "'Other',\n",
    "'Pet Products',\n",
    "'Non-Alcoholic Beverages',\n",
    "'Personal Care & Beauty',\n",
    "'Retailers',\n",
    "'Sports & Outdoors'\n",
    "]\n",
    "\n",
    "drop_words = ['tablespoon_jot',\n",
    "              'micro_dose',\n",
    "              'javy_make',\n",
    "              'coffe_make',\n",
    "             ]\n",
    "\n",
    "MIN_TERM_PCT = 0\n",
    "\n",
    "MAX_TERM_PCT = 100\n",
    "\n",
    "TERM_PERCENT_HEAD = 1\n",
    "\n",
    "TOP_N_WORDS = 8\n",
    "\n",
    "np.random.seed(42) # set seed for models for reproducibility\n",
    "\n",
    "stopwords_li = stopwords.words('english')\n",
    "punkts_li = list(string.punctuation)\n",
    "\n",
    "REVIEWS_PER_BRAND_TO_ANALYZE = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "439a907c-a3c2-4f25-b82a-7206b5de2095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(s, strip_str=\"=-_/\\+.:,'* 1234567890—\"):\n",
    "    custom_words_li = GROUP_CUSTOM_STOPWORDS + added_stopwords_li+stopwords_li + punkts_li + [\"\"]\n",
    "    return [w.lower().strip(strip_str) for w in word_tokenize(str(s)) if w.lower().strip(strip_str) not in custom_words_li]\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(w) for w in tokens]\n",
    "\n",
    "def unique_list(li):\n",
    "    deduped_li = list(set(li))\n",
    "    return deduped_li\n",
    "\n",
    "def bigram(tokens):\n",
    "    bi_tup = list(bigrams(tokens))\n",
    "    bi_li = ['_'.join(tup) for tup in bi_tup]\n",
    "    return bi_li\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b0048c-dbad-4036-8914-ed634c8c6de4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84a69a77-fa83-47df-b988-faf149483078",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_NAME = \"Coffee Concentrates\"\n",
    "# GROUP_NAME = 'Meat Substitutes'\n",
    "\n",
    "\n",
    "# When using Streamlit, leave list empty and un-comment cells below\n",
    "\n",
    "#Cereals\n",
    "NORMALIZED_URL_LI = [\n",
    "    \"jot.co\",\n",
    "    \"javycoffee.com\"\n",
    "\n",
    "    \n",
    "]\n",
    "\n",
    "PRIMARY_CATEGORIES = [\n",
    "\n",
    "]                      \n",
    "\n",
    "\n",
    "BRAND_NAME_LI = [\n",
    "    \"Jot\",\n",
    "    \"Javy\"\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "brand_name_di = dict(zip(NORMALIZED_URL_LI, BRAND_NAME_LI))\n",
    "\n",
    "external_revs_list = []\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "PROD_CAT_EXCLUDE_LI = ['Pet Products']\n",
    "    \n",
    "PRODUCT_NAME_NOT_CONTAINS_LI = ['toothpaste']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00661483-9a82-42d2-b41b-c2e6e3eb9b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4816a0bf-b10b-4e28-9837-6955b2367595",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_config = bigquery.QueryJobConfig(\n",
    "    query_parameters=[\n",
    "        bigquery.ArrayQueryParameter(\"url\", \"STRING\", NORMALIZED_URL_LI),\n",
    "        bigquery.ArrayQueryParameter(\"cols\", \"STRING\", REV_COLS),\n",
    "        bigquery.ArrayQueryParameter(\"brands\", \"STRING\", BRAND_NAME_LI)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23b0e599-ddc4-464e-930f-602a48af8100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_config = bigquery.QueryJobConfig(\n",
    "        query_parameters=[\n",
    "            bigquery.ArrayQueryParameter(\"url\", \"STRING\", NORMALIZED_URL_LI)\n",
    "        ]\n",
    ")\n",
    "max_date_query = \"\"\"\n",
    "    SELECT max(execution_date)\n",
    "    FROM `helio-staging.online_reviews.online_reviews__deduped_review__1_0`\n",
    "    where execution_date > DATE_ADD(current_date(), INTERVAL -10 DAY)\n",
    "    and normalized_url IS NOT NULL\n",
    "    \"\"\"\n",
    "query_job = client.query(\n",
    "    max_date_query,\n",
    "    # Location must match that of the dataset(s) referenced in the query.\n",
    "    location=\"US\",\n",
    "    job_config=job_config\n",
    ")  # API request - starts the query\n",
    "\n",
    "max_date = query_job.to_dataframe()['f0_'].astype('str')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a7921a5-de2f-41ff-bebd-87870e2aebc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-01-26'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f67c0f9-56e6-413d-8014-941b63a4b486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_config = bigquery.QueryJobConfig(\n",
    "    query_parameters=[\n",
    "        bigquery.ArrayQueryParameter(\"url\", \"STRING\", NORMALIZED_URL_LI),\n",
    "        bigquery.ScalarQueryParameter(\"max_date\", \"STRING\", max_date)\n",
    "    ]\n",
    ")\n",
    "review_query = \"\"\"\n",
    "    SELECT source_name,\n",
    "    normalized_url,\n",
    "    review_source_id,\n",
    "    reviewer_source_id,\n",
    "    product_name,\n",
    "    product_source_id,\n",
    "    review_date,\n",
    "    review_rating,\n",
    "    review_content\n",
    "    FROM `helio-staging.online_reviews.online_reviews__deduped_review__1_0`\n",
    "    WHERE (normalized_url IN UNNEST (@url)\n",
    "    OR product_name LIKE '%Jot Concentrated%'\n",
    "    )\n",
    "    AND execution_date = @max_date\n",
    "    \"\"\"\n",
    "query_job = client.query(\n",
    "    review_query,\n",
    "    # Location must match that of the dataset(s) referenced in the query.\n",
    "    location=\"US\",\n",
    "    job_config=job_config\n",
    ")  # API request - starts the query\n",
    "\n",
    "reviews = query_job.to_dataframe()\n",
    "reviews = reviews.loc[reviews.astype(str).drop_duplicates().index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05bab625-dca2-470c-b9b7-5cb7597fa48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_name</th>\n",
       "      <th>normalized_url</th>\n",
       "      <th>review_source_id</th>\n",
       "      <th>reviewer_source_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_source_id</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>amazon</td>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>R2SV9P1K3IWWH9</td>\n",
       "      <td>amzn1.account.AGPWAADHPMXOGSZNS5AIUEPR4IYQ</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-03-08 00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>THIS IS IT! I've been seeing ads for \"concent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>amazon</td>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>R1Q8VLQ79S37SE</td>\n",
       "      <td>amzn1.account.AGFQIEPCHM7OZQVKSJCXVE3SCPGA</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-03-17 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The bottle wasn't sealed correctly. The foil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>amazon</td>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>R2D2CN8LEMW5W2</td>\n",
       "      <td>amzn1.account.AFGCEHXJAOM4CMSA5AYBZHPZYYGA</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-03-03 00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This stuff is so good and really convenient!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>amazon</td>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>R2T3X0NUZMXLO2</td>\n",
       "      <td>amzn1.account.AHESZFF4KDLDJYT3FY6XRGOUWPTA</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-03-15 00:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Somewhat expensive. Convenient.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>amazon</td>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>RR26IKZ06FX4M</td>\n",
       "      <td>amzn1.account.AE3XIZ2JG6HNO4OMNYTZVNUCGXKA</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-03-24 00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I really like the convenience of it!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>amazon</td>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>R1K0DRQUE7H4RD</td>\n",
       "      <td>amzn1.account.AE3JLPTVSOPBQPHSMOSJYAOL4YBQ</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-03-24 00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Love the taste, love the compactness of the b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>amazon</td>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>R3P8RQ3A87P9MB</td>\n",
       "      <td>amzn1.account.AEWUZW3WW4HC3JEFLIFGCL2KZQUA</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-03-18 00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Convenient, great taste, love it!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>amazon</td>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>R3FTL5YWTT0RDS</td>\n",
       "      <td>amzn1.account.AERLY2PT4YHQZ47D6B3AHKVGLXVQ</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-03-11 00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great flavor and will save so much money not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>amazon</td>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>R1BSPIG8LQIMAA</td>\n",
       "      <td>amzn1.account.AHFLYVRZKR2EG6BD74B3RJPGXHVQ</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-03-04 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This stuff is terrible. Not in an offensive w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>amazon</td>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>R8YZVOIP6YOIW</td>\n",
       "      <td>amzn1.account.AHBRVFI4362PWMTPAYDW5X32OOBQ</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-03-23 00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I love how clean tasting JAVY is, as it makes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    source_name  normalized_url review_source_id  \\\n",
       "200      amazon  javycoffee.com   R2SV9P1K3IWWH9   \n",
       "201      amazon  javycoffee.com   R1Q8VLQ79S37SE   \n",
       "202      amazon  javycoffee.com   R2D2CN8LEMW5W2   \n",
       "203      amazon  javycoffee.com   R2T3X0NUZMXLO2   \n",
       "204      amazon  javycoffee.com    RR26IKZ06FX4M   \n",
       "..          ...             ...              ...   \n",
       "438      amazon  javycoffee.com   R1K0DRQUE7H4RD   \n",
       "439      amazon  javycoffee.com   R3P8RQ3A87P9MB   \n",
       "440      amazon  javycoffee.com   R3FTL5YWTT0RDS   \n",
       "441      amazon  javycoffee.com   R1BSPIG8LQIMAA   \n",
       "442      amazon  javycoffee.com    R8YZVOIP6YOIW   \n",
       "\n",
       "                             reviewer_source_id  \\\n",
       "200  amzn1.account.AGPWAADHPMXOGSZNS5AIUEPR4IYQ   \n",
       "201  amzn1.account.AGFQIEPCHM7OZQVKSJCXVE3SCPGA   \n",
       "202  amzn1.account.AFGCEHXJAOM4CMSA5AYBZHPZYYGA   \n",
       "203  amzn1.account.AHESZFF4KDLDJYT3FY6XRGOUWPTA   \n",
       "204  amzn1.account.AE3XIZ2JG6HNO4OMNYTZVNUCGXKA   \n",
       "..                                          ...   \n",
       "438  amzn1.account.AE3JLPTVSOPBQPHSMOSJYAOL4YBQ   \n",
       "439  amzn1.account.AEWUZW3WW4HC3JEFLIFGCL2KZQUA   \n",
       "440  amzn1.account.AERLY2PT4YHQZ47D6B3AHKVGLXVQ   \n",
       "441  amzn1.account.AHFLYVRZKR2EG6BD74B3RJPGXHVQ   \n",
       "442  amzn1.account.AHBRVFI4362PWMTPAYDW5X32OOBQ   \n",
       "\n",
       "                                          product_name product_source_id  \\\n",
       "200  Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "201  Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "202  Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "203  Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "204  Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "..                                                 ...               ...   \n",
       "438  Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "439  Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "440  Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "441  Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "442  Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "\n",
       "             review_date  review_rating  \\\n",
       "200  2021-03-08 00:00:00            5.0   \n",
       "201  2021-03-17 00:00:00            1.0   \n",
       "202  2021-03-03 00:00:00            5.0   \n",
       "203  2021-03-15 00:00:00            4.0   \n",
       "204  2021-03-24 00:00:00            5.0   \n",
       "..                   ...            ...   \n",
       "438  2021-03-24 00:00:00            5.0   \n",
       "439  2021-03-18 00:00:00            5.0   \n",
       "440  2021-03-11 00:00:00            5.0   \n",
       "441  2021-03-04 00:00:00            1.0   \n",
       "442  2021-03-23 00:00:00            5.0   \n",
       "\n",
       "                                        review_content  \n",
       "200   THIS IS IT! I've been seeing ads for \"concent...  \n",
       "201   The bottle wasn't sealed correctly. The foil ...  \n",
       "202      This stuff is so good and really convenient!   \n",
       "203                   Somewhat expensive. Convenient.   \n",
       "204           I really like the convenience of it!!!!   \n",
       "..                                                 ...  \n",
       "438   Love the taste, love the compactness of the b...  \n",
       "439                Convenient, great taste, love it!!   \n",
       "440   Great flavor and will save so much money not ...  \n",
       "441   This stuff is terrible. Not in an offensive w...  \n",
       "442   I love how clean tasting JAVY is, as it makes...  \n",
       "\n",
       "[243 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape\n",
    "reviews = reviews[reviews[\"normalized_url\"]!=\"jot.co\"]\n",
    "reviews[\"normalized_url\"] = reviews[\"normalized_url\"].replace(\"acuitybrands.com\",\"jot.co\")\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "324f3bd1-8581-4102-a479-e6c380682370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcf58c7c-eff6-4406-b572-e66f195c65a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Product Category Data\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT product_source_id, parent_category, primary_category\n",
    "    FROM `helio-staging.taxonomy.product_taxonomy__1_0`\n",
    "    WHERE normalized_url IN UNNEST (@url)\n",
    "\n",
    "    \"\"\"\n",
    "query_job = client.query(\n",
    "    query,\n",
    "    # Location must match that of the dataset(s) referenced in the query.\n",
    "    location=\"US\",\n",
    "    job_config=job_config\n",
    ")  # API request - starts the query\n",
    "\n",
    "prod_cat = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9fd54d7a-07ee-4b0a-beb4-52363b217eac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All primary categories\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT distinct parent_category\n",
    "    FROM `helio-staging.taxonomy.product_taxonomy__1_0`\n",
    "    \"\"\"\n",
    "query_job = client.query(\n",
    "    query,\n",
    "    # Location must match that of the dataset(s) referenced in the query.\n",
    "    location=\"US\",\n",
    "    job_config=job_config\n",
    ")  # API request - starts the query\n",
    "\n",
    "cat_list = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30e4eb10-d267-4405-a719-1223184b0689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Join reviews with product categories\n",
    "\n",
    "reviews = pd.merge(\n",
    "    reviews, \n",
    "    prod_cat, \n",
    "    on='product_source_id', how='left').drop_duplicates(subset=['source_name', 'review_source_id'])\n",
    "\n",
    "# Filter out excluded categories, excluded product name terms\n",
    "PROD_CAT_EXCLUDE_LI = ['Pet Products']\n",
    "\n",
    "for term in PROD_CAT_EXCLUDE_LI:\n",
    "    reviews = reviews[(~reviews['parent_category'].fillna('').str.contains(term))]\n",
    "\n",
    "    \n",
    "PRODUCT_NAME_NOT_CONTAINS_LI = ['Purina', 'Krill']\n",
    "for term in PRODUCT_NAME_NOT_CONTAINS_LI:\n",
    "    reviews = reviews[~(reviews['product_name'].str.lower().fillna('').str.contains(term.lower()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9acefad-1843-4237-be6a-74d0947cc04d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cdf59dd1-c78b-478e-96b4-4a36e19c1d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read external CSVs\n",
    "\n",
    "if external_revs_list != []:\n",
    "    cleaned_external_review_list = []\n",
    "    for external_revs_csv in external_revs_list:  \n",
    "        external_revs_csv['review_rating']=pd.to_numeric(external_revs_csv['review_rating'], downcast='float')\n",
    "        external_revs_csv['source_name'] = 'DTC'\n",
    "        # Checking for static columns, to add blanksto data frame\n",
    "        # Then checking for incrementing columns, which we'll set as the index, assuming they are unique reviewers and reviews\n",
    "        static_columns = ['product_name', 'product_source_id']\n",
    "        incrementing_columns = ['review_source_id','reviewer_source_id']\n",
    "\n",
    "        for column_name in static_columns:\n",
    "            if column_name not in external_revs_csv:\n",
    "                external_revs_csv[column_name] = ''\n",
    "            else:\n",
    "                pass\n",
    "        for column_name in incrementing_columns:\n",
    "            if column_name not in external_revs_csv:\n",
    "                external_revs_csv[column_name]=external_revs_csv.index\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        # selecting the same columns as internal reviews CSV\n",
    "        external_revs_csv = external_revs_csv[brand_revs.columns]\n",
    "        cleaned_external_review_list.append(external_revs_csv)\n",
    "\n",
    "    external_revs_csv = pd.concat(cleaned_external_review_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cbbdbf29-8515-4a18-a87c-88f1f0e0307d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Join external CSVs and clean reviews\n",
    "\n",
    "if external_revs_list != []:\n",
    "    reviews = reviews.union(external_revs_sdf)\n",
    "\n",
    "reviews['review_content'] = reviews['review_content'].str.replace('/[^a-zA-Z0-9]/g', '', regex=True);\n",
    "\n",
    "# removing hypertext from reviews\n",
    "reviews['review_content'] = reviews['review_content'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
    "\n",
    "# removing contractions from reviews\n",
    "reviews['review_content'] = reviews['review_content'].apply(lambda x: [contractions.fix(word) for word in x.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07556303-4013-486b-ae1a-256b7bc7a649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get most recent n reviews\n",
    "\n",
    "reviews = (reviews\n",
    "           .sort_values('review_date',ascending = False)\n",
    "           .groupby('normalized_url')\n",
    "           .head(REVIEWS_PER_BRAND_TO_ANALYZE)\n",
    "          )\n",
    "\n",
    "reviews_count = reviews.groupby('normalized_url').agg({'review_source_id':'count'}).reset_index().rename(columns={\"review_source_id\": \"rev_count\"})\n",
    "\n",
    "reviews = pd.merge(reviews_count, reviews, on=['normalized_url'])\n",
    "\n",
    "#reviews = reviews[reviews['primary_category'].str.contains('|'.join(PRIMARY_CATEGORIES), na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b3684-02a9-4294-8601-1f6ae1b04f74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b4aee6d-f8ee-4b6e-8403-a8faaac40cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews[reviews[\"normalized_url\"]==\"jot.co\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f648a208-3b3c-44de-8e69-581962020d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_reviews = reviews.copy()\n",
    "tokenized_reviews['tokenized_review'] = tokenized_reviews['review_content'].apply(lambda x: lemmatize(tokenize(x)))\n",
    "tokenized_reviews = tokenized_reviews.dropna(subset=['tokenized_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0f57cd5-03a2-4323-a7c5-2c71cd5ee017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unibi_reviews = tokenized_reviews.copy()\n",
    "\n",
    "unibi_reviews['unibi'] = unibi_reviews['tokenized_review'].apply(lambda x: unique_list(bigram(x)+x))\n",
    "unibi_reviews = unibi_reviews.loc[unibi_reviews.astype(str).drop_duplicates().index]\n",
    "\n",
    "unibi_words = unibi_reviews.copy()\n",
    "unibi_words['unibi_word'] = unibi_words['unibi']\n",
    "unibi_words = unibi_words.explode('unibi_word')\n",
    "unibi_words= unibi_words[~unibi_words[\"unibi_word\"].isin(drop_words)]\n",
    "#unibi_words=unibi_words[unibi_words[\"parent_category\"]==\"Food\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b65e537-2804-42ad-a31e-bdc7f8bb4190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized_url</th>\n",
       "      <th>rev_count</th>\n",
       "      <th>source_name</th>\n",
       "      <th>review_source_id</th>\n",
       "      <th>reviewer_source_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_source_id</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_content</th>\n",
       "      <th>parent_category</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>tokenized_review</th>\n",
       "      <th>unibi</th>\n",
       "      <th>unibi_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>243</td>\n",
       "      <td>amazon</td>\n",
       "      <td>R2UQVJZ8O0KDXE</td>\n",
       "      <td>amzn1.account.AGMEQMSQG7CXIVRLNMDOURR33CAQ</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-03-26 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[This, coffee, tastes, horrible., Bitter, and,...</td>\n",
       "      <td>Non-Alcoholic Beverages</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>[coffee, taste, horrible, bitter, burnt]</td>\n",
       "      <td>[horrible, coffee, horrible_bitter, bitter_bur...</td>\n",
       "      <td>horrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>243</td>\n",
       "      <td>amazon</td>\n",
       "      <td>R2UQVJZ8O0KDXE</td>\n",
       "      <td>amzn1.account.AGMEQMSQG7CXIVRLNMDOURR33CAQ</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-03-26 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[This, coffee, tastes, horrible., Bitter, and,...</td>\n",
       "      <td>Non-Alcoholic Beverages</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>[coffee, taste, horrible, bitter, burnt]</td>\n",
       "      <td>[horrible, coffee, horrible_bitter, bitter_bur...</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>243</td>\n",
       "      <td>amazon</td>\n",
       "      <td>R2UQVJZ8O0KDXE</td>\n",
       "      <td>amzn1.account.AGMEQMSQG7CXIVRLNMDOURR33CAQ</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-03-26 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[This, coffee, tastes, horrible., Bitter, and,...</td>\n",
       "      <td>Non-Alcoholic Beverages</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>[coffee, taste, horrible, bitter, burnt]</td>\n",
       "      <td>[horrible, coffee, horrible_bitter, bitter_bur...</td>\n",
       "      <td>horrible_bitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>243</td>\n",
       "      <td>amazon</td>\n",
       "      <td>R2UQVJZ8O0KDXE</td>\n",
       "      <td>amzn1.account.AGMEQMSQG7CXIVRLNMDOURR33CAQ</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-03-26 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[This, coffee, tastes, horrible., Bitter, and,...</td>\n",
       "      <td>Non-Alcoholic Beverages</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>[coffee, taste, horrible, bitter, burnt]</td>\n",
       "      <td>[horrible, coffee, horrible_bitter, bitter_bur...</td>\n",
       "      <td>bitter_burnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>243</td>\n",
       "      <td>amazon</td>\n",
       "      <td>R2UQVJZ8O0KDXE</td>\n",
       "      <td>amzn1.account.AGMEQMSQG7CXIVRLNMDOURR33CAQ</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-03-26 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[This, coffee, tastes, horrible., Bitter, and,...</td>\n",
       "      <td>Non-Alcoholic Beverages</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>[coffee, taste, horrible, bitter, burnt]</td>\n",
       "      <td>[horrible, coffee, horrible_bitter, bitter_bur...</td>\n",
       "      <td>coffee_taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>243</td>\n",
       "      <td>amazon</td>\n",
       "      <td>R4H31SY96NBTP</td>\n",
       "      <td>amzn1.account.AFQPSWWJP2R2PXNC5RCINEMWRIBQ</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-01-26 00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[Would, recommend, 100/10!, I, saved, so, much...</td>\n",
       "      <td>Non-Alcoholic Beverages</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>[would, saved, much, time, morning, hate, morn...</td>\n",
       "      <td>[interact, line, home, time_morning, saved, wa...</td>\n",
       "      <td>happy_make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>243</td>\n",
       "      <td>amazon</td>\n",
       "      <td>R4H31SY96NBTP</td>\n",
       "      <td>amzn1.account.AFQPSWWJP2R2PXNC5RCINEMWRIBQ</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-01-26 00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[Would, recommend, 100/10!, I, saved, so, much...</td>\n",
       "      <td>Non-Alcoholic Beverages</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>[would, saved, much, time, morning, hate, morn...</td>\n",
       "      <td>[interact, line, home, time_morning, saved, wa...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>243</td>\n",
       "      <td>amazon</td>\n",
       "      <td>R4H31SY96NBTP</td>\n",
       "      <td>amzn1.account.AFQPSWWJP2R2PXNC5RCINEMWRIBQ</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-01-26 00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[Would, recommend, 100/10!, I, saved, so, much...</td>\n",
       "      <td>Non-Alcoholic Beverages</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>[would, saved, much, time, morning, hate, morn...</td>\n",
       "      <td>[interact, line, home, time_morning, saved, wa...</td>\n",
       "      <td>right_front</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>243</td>\n",
       "      <td>amazon</td>\n",
       "      <td>R4H31SY96NBTP</td>\n",
       "      <td>amzn1.account.AFQPSWWJP2R2PXNC5RCINEMWRIBQ</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-01-26 00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[Would, recommend, 100/10!, I, saved, so, much...</td>\n",
       "      <td>Non-Alcoholic Beverages</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>[would, saved, much, time, morning, hate, morn...</td>\n",
       "      <td>[interact, line, home, time_morning, saved, wa...</td>\n",
       "      <td>home_waiting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>243</td>\n",
       "      <td>amazon</td>\n",
       "      <td>R4H31SY96NBTP</td>\n",
       "      <td>amzn1.account.AFQPSWWJP2R2PXNC5RCINEMWRIBQ</td>\n",
       "      <td>Javy Coffee Microdose 30X Liquid Coffee Concen...</td>\n",
       "      <td>B08SJ4HVSY</td>\n",
       "      <td>2021-01-26 00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[Would, recommend, 100/10!, I, saved, so, much...</td>\n",
       "      <td>Non-Alcoholic Beverages</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>[would, saved, much, time, morning, hate, morn...</td>\n",
       "      <td>[interact, line, home, time_morning, saved, wa...</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7149 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     normalized_url  rev_count source_name review_source_id  \\\n",
       "0    javycoffee.com        243      amazon   R2UQVJZ8O0KDXE   \n",
       "0    javycoffee.com        243      amazon   R2UQVJZ8O0KDXE   \n",
       "0    javycoffee.com        243      amazon   R2UQVJZ8O0KDXE   \n",
       "0    javycoffee.com        243      amazon   R2UQVJZ8O0KDXE   \n",
       "0    javycoffee.com        243      amazon   R2UQVJZ8O0KDXE   \n",
       "..              ...        ...         ...              ...   \n",
       "242  javycoffee.com        243      amazon    R4H31SY96NBTP   \n",
       "242  javycoffee.com        243      amazon    R4H31SY96NBTP   \n",
       "242  javycoffee.com        243      amazon    R4H31SY96NBTP   \n",
       "242  javycoffee.com        243      amazon    R4H31SY96NBTP   \n",
       "242  javycoffee.com        243      amazon    R4H31SY96NBTP   \n",
       "\n",
       "                             reviewer_source_id  \\\n",
       "0    amzn1.account.AGMEQMSQG7CXIVRLNMDOURR33CAQ   \n",
       "0    amzn1.account.AGMEQMSQG7CXIVRLNMDOURR33CAQ   \n",
       "0    amzn1.account.AGMEQMSQG7CXIVRLNMDOURR33CAQ   \n",
       "0    amzn1.account.AGMEQMSQG7CXIVRLNMDOURR33CAQ   \n",
       "0    amzn1.account.AGMEQMSQG7CXIVRLNMDOURR33CAQ   \n",
       "..                                          ...   \n",
       "242  amzn1.account.AFQPSWWJP2R2PXNC5RCINEMWRIBQ   \n",
       "242  amzn1.account.AFQPSWWJP2R2PXNC5RCINEMWRIBQ   \n",
       "242  amzn1.account.AFQPSWWJP2R2PXNC5RCINEMWRIBQ   \n",
       "242  amzn1.account.AFQPSWWJP2R2PXNC5RCINEMWRIBQ   \n",
       "242  amzn1.account.AFQPSWWJP2R2PXNC5RCINEMWRIBQ   \n",
       "\n",
       "                                          product_name product_source_id  \\\n",
       "0    Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "0    Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "0    Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "0    Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "0    Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "..                                                 ...               ...   \n",
       "242  Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "242  Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "242  Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "242  Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "242  Javy Coffee Microdose 30X Liquid Coffee Concen...        B08SJ4HVSY   \n",
       "\n",
       "             review_date  review_rating  \\\n",
       "0    2021-03-26 00:00:00            2.0   \n",
       "0    2021-03-26 00:00:00            2.0   \n",
       "0    2021-03-26 00:00:00            2.0   \n",
       "0    2021-03-26 00:00:00            2.0   \n",
       "0    2021-03-26 00:00:00            2.0   \n",
       "..                   ...            ...   \n",
       "242  2021-01-26 00:00:00            5.0   \n",
       "242  2021-01-26 00:00:00            5.0   \n",
       "242  2021-01-26 00:00:00            5.0   \n",
       "242  2021-01-26 00:00:00            5.0   \n",
       "242  2021-01-26 00:00:00            5.0   \n",
       "\n",
       "                                        review_content  \\\n",
       "0    [This, coffee, tastes, horrible., Bitter, and,...   \n",
       "0    [This, coffee, tastes, horrible., Bitter, and,...   \n",
       "0    [This, coffee, tastes, horrible., Bitter, and,...   \n",
       "0    [This, coffee, tastes, horrible., Bitter, and,...   \n",
       "0    [This, coffee, tastes, horrible., Bitter, and,...   \n",
       "..                                                 ...   \n",
       "242  [Would, recommend, 100/10!, I, saved, so, much...   \n",
       "242  [Would, recommend, 100/10!, I, saved, so, much...   \n",
       "242  [Would, recommend, 100/10!, I, saved, so, much...   \n",
       "242  [Would, recommend, 100/10!, I, saved, so, much...   \n",
       "242  [Would, recommend, 100/10!, I, saved, so, much...   \n",
       "\n",
       "             parent_category primary_category  \\\n",
       "0    Non-Alcoholic Beverages           Coffee   \n",
       "0    Non-Alcoholic Beverages           Coffee   \n",
       "0    Non-Alcoholic Beverages           Coffee   \n",
       "0    Non-Alcoholic Beverages           Coffee   \n",
       "0    Non-Alcoholic Beverages           Coffee   \n",
       "..                       ...              ...   \n",
       "242  Non-Alcoholic Beverages           Coffee   \n",
       "242  Non-Alcoholic Beverages           Coffee   \n",
       "242  Non-Alcoholic Beverages           Coffee   \n",
       "242  Non-Alcoholic Beverages           Coffee   \n",
       "242  Non-Alcoholic Beverages           Coffee   \n",
       "\n",
       "                                      tokenized_review  \\\n",
       "0             [coffee, taste, horrible, bitter, burnt]   \n",
       "0             [coffee, taste, horrible, bitter, burnt]   \n",
       "0             [coffee, taste, horrible, bitter, burnt]   \n",
       "0             [coffee, taste, horrible, bitter, burnt]   \n",
       "0             [coffee, taste, horrible, bitter, burnt]   \n",
       "..                                                 ...   \n",
       "242  [would, saved, much, time, morning, hate, morn...   \n",
       "242  [would, saved, much, time, morning, hate, morn...   \n",
       "242  [would, saved, much, time, morning, hate, morn...   \n",
       "242  [would, saved, much, time, morning, hate, morn...   \n",
       "242  [would, saved, much, time, morning, hate, morn...   \n",
       "\n",
       "                                                 unibi       unibi_word  \n",
       "0    [horrible, coffee, horrible_bitter, bitter_bur...         horrible  \n",
       "0    [horrible, coffee, horrible_bitter, bitter_bur...           coffee  \n",
       "0    [horrible, coffee, horrible_bitter, bitter_bur...  horrible_bitter  \n",
       "0    [horrible, coffee, horrible_bitter, bitter_bur...     bitter_burnt  \n",
       "0    [horrible, coffee, horrible_bitter, bitter_bur...     coffee_taste  \n",
       "..                                                 ...              ...  \n",
       "242  [interact, line, home, time_morning, saved, wa...       happy_make  \n",
       "242  [interact, line, home, time_morning, saved, wa...            happy  \n",
       "242  [interact, line, home, time_morning, saved, wa...      right_front  \n",
       "242  [interact, line, home, time_morning, saved, wa...     home_waiting  \n",
       "242  [interact, line, home, time_morning, saved, wa...             make  \n",
       "\n",
       "[7149 rows x 15 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unibi_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d709c3b3-78f2-4675-a6bd-083082fac885",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sdf = pd.DataFrame(unibi_reviews.groupby('normalized_url').unibi.apply(sum)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04750519-ac57-40bd-9bd8-100543d5b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 50)\n",
    "\n",
    "#tokenized_reviews[(tokenized_reviews['review_source_id']=='232203656')]\n",
    "\n",
    "grouped_sdf['unibi_str'] = [','.join(map(str, l)) for l in grouped_sdf['unibi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4ffa0762-989a-4f78-b4ac-0ebd7e92053d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized_url</th>\n",
       "      <th>unibi</th>\n",
       "      <th>unibi_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>javycoffee.com</td>\n",
       "      <td>[horrible, coffee, horrible_bitter, bitter_bur...</td>\n",
       "      <td>horrible,coffee,horrible_bitter,bitter_burnt,c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   normalized_url                                              unibi  \\\n",
       "0  javycoffee.com  [horrible, coffee, horrible_bitter, bitter_bur...   \n",
       "\n",
       "                                           unibi_str  \n",
       "0  horrible,coffee,horrible_bitter,bitter_burnt,c...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "47974363-123e-477f-a459-ae2c4e0eb582",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max_df corresponds to < documents than min_df",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21852/2239236212.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# just send in all your docs here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtfidf_vectorizer_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouped_sdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unibi_str'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# get the first vector out (for the first document)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2075\u001b[0m         \"\"\"\n\u001b[1;32m   2076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2078\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1342\u001b[0m             )\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_doc_count\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_doc_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_df corresponds to < documents than min_df\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max_df corresponds to < documents than min_df"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "\n",
    "for i in range(len(grouped_sdf)):    \n",
    "# settings that you use for count vectorizer will go here \n",
    "    tfidf_vectorizer=TfidfVectorizer(\n",
    "        norm=None,\n",
    "        sublinear_tf=False,\n",
    "        use_idf=True,\n",
    "        lowercase=False,\n",
    "        stop_words='english',\n",
    "        smooth_idf=True,\n",
    "        max_df = len(grouped_sdf['normalized_url'])-1\n",
    "    ) \n",
    "\n",
    "    # just send in all your docs here \n",
    "    tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(grouped_sdf['unibi_str'])\n",
    "\n",
    "    # get the first vector out (for the first document) \n",
    "    first_vector_tfidfvectorizer=tfidf_vectorizer_vectors[i]\n",
    "\n",
    "    # place tf-idf values in a pandas data frame \n",
    "    df = pd.DataFrame(first_vector_tfidfvectorizer.T.todense(), index=tfidf_vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "    joined_df = unibi_words[(unibi_words['normalized_url']==grouped_sdf.reset_index()['normalized_url'][i])].join(df, on='unibi_word', how='inner', lsuffix='_left', rsuffix='_right')\n",
    "    frames.append(joined_df)\n",
    "\n",
    "df = pd.concat(frames)\n",
    "#reviews = unibi_reviews[(unibi_reviews['normalized_url'] == url)]\n",
    "#joined_df = unibi_reviews.join(df, on='unibi_word', how='inner', lsuffix='_left', rsuffix='_right')\n",
    "sorted_df = df[['normalized_url', 'unibi_word', 'tfidf']].sort_values(by=['normalized_url', \"tfidf\"],ascending=False).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb04098e-fceb-4ee9-8e28-7119e03d8721",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_output = sorted_df.groupby('normalized_url').head(TOP_N_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de16d647-d2cf-4e84-8bf4-eaaf46b09855",
   "metadata": {},
   "outputs": [],
   "source": [
    "unibi_reviews_grouped = unibi_words.groupby(['normalized_url', 'unibi_word']).agg({'review_rating':'mean', 'review_source_id':'count'})\n",
    "\n",
    "unibi_reviews_grouped = unibi_reviews_grouped.rename(columns={\"review_rating\": \"avg_rating\", \"review_source_id\": \"review_count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a8fa7-9f54-494e-8e3d-941d0c9297b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rating_tfidf = pd.merge(unibi_reviews_grouped, tf_idf_output, on=['normalized_url', 'unibi_word'], how='inner').sort_values(by=['normalized_url', \"tfidf\"],ascending=False)[['normalized_url','unibi_word', 'tfidf', 'avg_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d7be2e-a0fb-4b20-a97f-0273f82e5c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpc = pd.read_csv(\"coffee kpc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde92d43-7ca2-4442-9871-aa95e6f2617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpc['attribute_prevalence'] = kpc['attribute_prevalence']/kpc['attribute_prevalence'].sum()\n",
    "kpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef69d1f-0546-4bf4-8868-67d9d939be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map aspects to words\n",
    "kpc_di = dict(zip(kpc[\"seed_words\"],kpc[\"attribute_name\"]))\n",
    "seed_words = kpc[\"seed_words\"].tolist()\n",
    "attributes = kpc[\"attribute_name\"].tolist()\n",
    "\n",
    "def aspect_map (x):\n",
    "    for i in seed_words:\n",
    "        if x in i.split(\",\"):\n",
    "            return kpc_di[i]\n",
    "\n",
    "\n",
    "unibi_words[\"aspect\"] = unibi_words[\"unibi_word\"].map(aspect_map)\n",
    "unibi_words[\"brand\"] = unibi_words[\"normalized_url\"].map(brand_name_di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0e5048-01f7-436c-ae43-aca0b6af98dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unibi_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ad42a9-04eb-44a7-b09f-bd2a8d8cfaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate aspect rating\n",
    "#unibi_words.groupby([\"brand\", \"aspect\"])[\"review_rating\"].mean()\n",
    "brand_aspects = unibi_words[unibi_words[\"aspect\"].isin(attributes)].groupby([\"brand\", \"aspect\"])[\"review_rating\"].mean().reset_index()\n",
    "rating_data = brand_aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34e3bd1-4058-4e60-8455-2b2326a84dea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rating_data[\"asp_prev\"] = rating_data[\"aspect\"].map(dict(zip(kpc[\"kpc_name\"],kpc[\"attribute_prevalence\"])))\n",
    "rating_data = rating_data.sort_values(by=\"asp_prev\", ascending=False)\n",
    "rating_data= rating_data.sort_values(by=\"brand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dbdd4a-7232-4194-a979-e104d4b1eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "bar_data =  px.bar(\n",
    "        kpc,\n",
    "        x='attribute_name',\n",
    "        y='attribute_prevalence',\n",
    "        barmode='group',\n",
    "    )\n",
    "\n",
    "line_data = px.scatter(\n",
    "        rating_data,\n",
    "        x='aspect',\n",
    "        y=\"review_rating\",\n",
    "        color='brand',\n",
    "        color_discrete_sequence=[\"blue\", \"goldenrod\", \"magenta\"],\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(categoryorder='array', categoryarray= ['Flavor', 'Value for money','Packaging','Freshness','Giftable','Easy to use'])\n",
    "\n",
    "for data in line_data.data:\n",
    "    fig.add_trace(data.update(mode='markers+lines'), secondary_y=True)\n",
    "    \n",
    "\n",
    "for data in bar_data.data:\n",
    "    fig.add_trace(data)\n",
    "    \n",
    "fig.update_traces(marker=dict(color=\"lightgray\"),selector=dict(type=\"bar\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"KPC for Select {GROUP_NAME} Brands\",\n",
    "    xaxis_title=\"Aspect\",\n",
    "    yaxis_title=\"Overall Normalized Percent Weight\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "fig.update_yaxes(\n",
    "    range=[1,5],\n",
    "    title=\"Brand Stars Rating (out of 5)\",\n",
    "    secondary_y=True\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    autorange = True,\n",
    "    tickformat='.0%',\n",
    "    secondary_y=False\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    plot_bgcolor=\"white\",\n",
    "    title={\"x\": 0.5},\n",
    "    coloraxis={\"autocolorscale\": True},\n",
    "    paper_bgcolor =\"rgba(0,0,0,0)\",\n",
    "  \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23ae291-14ac-46ec-9958-ccaae98dfc61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78e9301-2dee-4a1a-a3f5-e96cd5d69dab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
